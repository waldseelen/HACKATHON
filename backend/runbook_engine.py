"""
LogSense AI â€“ Automated Runbook Engine
========================================
Generates context-aware recovery playbooks based on detected cascade
failure patterns and signals. Each runbook is a structured, step-by-step
recovery plan tailored to the specific failure mode.

Runbook Features:
  â€¢ Phased recovery (Emergency Stop â†’ Cleanup â†’ Restart â†’ Monitor)
  â€¢ Conditional action matrix
  â€¢ Verification checkpoints
  â€¢ Rollback triggers
  â€¢ Estimated time-to-recovery
"""

import logging
from dataclasses import dataclass, field
from typing import Optional

from cascade_detector import CascadeDetectionResult, SignalType

logger = logging.getLogger("logsense.runbook")


# â”€â”€ Runbook Data Structures â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@dataclass
class RunbookStep:
    """A single step in a recovery runbook."""
    order: int
    title: str
    description: str
    commands: list[str]
    phase: str  # PHASE_1 through PHASE_4
    estimated_minutes: int = 2
    requires_confirmation: bool = False
    rollback_command: Optional[str] = None
    verification: Optional[str] = None

    def to_dict(self) -> dict:
        d = {
            "order": self.order,
            "title": self.title,
            "description": self.description,
            "commands": self.commands,
            "phase": self.phase,
            "estimated_minutes": self.estimated_minutes,
            "requires_confirmation": self.requires_confirmation,
        }
        if self.rollback_command:
            d["rollback_command"] = self.rollback_command
        if self.verification:
            d["verification"] = self.verification
        return d


@dataclass
class Runbook:
    """Complete recovery runbook for a cascade failure."""
    id: str
    title: str
    severity: str
    description: str
    cascade_type: str
    detected_signals: list[str]
    estimated_recovery_minutes: int
    steps: list[RunbookStep]
    conditional_actions: list[dict]
    rollback_triggers: list[str]
    monitoring_commands: list[str]
    post_mortem_checklist: list[str]

    def to_dict(self) -> dict:
        return {
            "id": self.id,
            "title": self.title,
            "severity": self.severity,
            "description": self.description,
            "cascade_type": self.cascade_type,
            "detected_signals": self.detected_signals,
            "estimated_recovery_minutes": self.estimated_recovery_minutes,
            "steps": [s.to_dict() for s in self.steps],
            "conditional_actions": self.conditional_actions,
            "rollback_triggers": self.rollback_triggers,
            "monitoring_commands": self.monitoring_commands,
            "post_mortem_checklist": self.post_mortem_checklist,
            "total_steps": len(self.steps),
            "phases": list(set(s.phase for s in self.steps)),
        }


# â”€â”€ Runbook Templates â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class RunbookEngine:
    """Generates recovery runbooks based on cascade detection results."""

    def generate(self, detection: CascadeDetectionResult) -> Optional[Runbook]:
        """Generate a runbook from cascade detection result."""
        if not detection.is_cascade:
            return None

        runbook_id = detection.runbook_id
        generator = self._GENERATORS.get(runbook_id)

        if not generator:
            logger.warning(f"No runbook template for: {runbook_id}")
            return self._generic_runbook(detection)

        return generator(self, detection)

    # â”€â”€ OOM Kill Loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _oom_kill_loop(self, det: CascadeDetectionResult) -> Runbook:
        steps = [
            RunbookStep(
                order=1,
                title="Trafik Kesimi - Yeni Request Durdur",
                description="OOM dÃ¶ngÃ¼sÃ¼nden Ã§Ä±kmak iÃ§in Ã¶nce trafiÄŸi kes. "
                            "Mevcut baÄŸlantÄ±lar timeout ile kapansÄ±n.",
                commands=[
                    "kubectl scale deployment <app> --replicas=0 --namespace=prod",
                    "# veya: nginx upstream'i down olarak iÅŸaretle",
                ],
                phase="PHASE_1",
                estimated_minutes=1,
                verification="kubectl get pods -n prod | grep <app> â†’ 0 running",
            ),
            RunbookStep(
                order=2,
                title="Unhealthy Pod'larÄ± Temizle",
                description="CrashLoopBackOff ve OOMKilled pod'larÄ± force delete ile temizle.",
                commands=[
                    "kubectl delete pod <pod-name> --force --grace-period=0",
                    "kubectl get pods -n prod | grep -E 'OOMKilled|CrashLoop|Error'",
                ],
                phase="PHASE_1",
                estimated_minutes=1,
            ),
            RunbookStep(
                order=3,
                title="Memory Limit 2x ArtÄ±r",
                description="Resource quota ve deployment memory limitlerini geÃ§ici olarak 2 katÄ±na Ã§Ä±kar.",
                commands=[
                    "kubectl set resources deployment <app> --limits=memory=2Gi --requests=memory=1Gi -n prod",
                    "# veya: kubectl edit resourcequota -n prod â†’ memory.limit 2x yap",
                ],
                phase="PHASE_2",
                estimated_minutes=2,
                requires_confirmation=True,
                rollback_command="kubectl set resources deployment <app> --limits=memory=1Gi --requests=memory=512Mi -n prod",
            ),
            RunbookStep(
                order=4,
                title="Heap Dump Analizi (JVM/Node.js varsa)",
                description="Memory leak tespit etmek iÃ§in heap dump oluÅŸtur ve GC tuning yap.",
                commands=[
                    "# JVM: jmap -dump:format=b,file=/tmp/heap.hprof <pid>",
                    "# Node: node --heapsnapshot-signal=SIGUSR2 â†’ kill -SIGUSR2 <pid>",
                    "# GC Tuning: -XX:MaxRAMPercentage=75 -XX:+UseG1GC",
                    "# Node: --max-old-space-size=768 (limit'in %75'i)",
                ],
                phase="PHASE_2",
                estimated_minutes=3,
            ),
            RunbookStep(
                order=5,
                title="Servisi Kademeli BaÅŸlat",
                description="Memory limitleri artÄ±rÄ±ldÄ±ktan sonra 50% kapasite ile baÅŸla. "
                            "3 dakika izle, OOM yoksa tam kapasiteye Ã§Ä±k.",
                commands=[
                    "kubectl scale deployment <app> --replicas=2 -n prod  # 50% kapasite",
                    "kubectl top pods -n prod -l app=<app>  # Memory izle",
                    "# 3dk OOM yoksa:",
                    "kubectl scale deployment <app> --replicas=4 -n prod  # Tam kapasite",
                ],
                phase="PHASE_3",
                estimated_minutes=5,
                verification="kubectl get pods -l app=<app> â†’ 0 restarts, memory < %75",
            ),
            RunbookStep(
                order=6,
                title="Memory Alert EÅŸiÄŸini DÃ¼ÅŸÃ¼r",
                description="Erken uyarÄ± iÃ§in Prometheus alert eÅŸiÄŸini %70'e dÃ¼ÅŸÃ¼r.",
                commands=[
                    "# Prometheus alert rule: memory_usage > 70% (eski: 85%)",
                    "# Grafana dashboard memory panel'ini gÃ¼ncelle",
                ],
                phase="PHASE_4",
                estimated_minutes=2,
            ),
        ]

        return Runbook(
            id="oom_kill_loop",
            title="ğŸ”´ OOM Kill Loop Recovery",
            severity=det.severity,
            cascade_type=det.cascade_type,
            description=det.description,
            detected_signals=det.detected_signals,
            estimated_recovery_minutes=14,
            steps=steps,
            conditional_actions=[
                {"condition": "3dk iÃ§inde OOM tekrarÄ±", "action": "Full rollback + traffic external failover"},
                {"condition": "GC overhead > %50", "action": "Heap dump + GC tuning (JVM: G1GC, Node: max-old-space-size)"},
                {"condition": "Memory leak doÄŸrulandÄ±", "action": "Hotfix deploy + canary release"},
            ],
            rollback_triggers=[
                "3dk iÃ§inde OOM tekrarÄ±",
                "Memory kullanÄ±mÄ± %95 Ã¼zeri kalÄ±yor",
                "Pod restart sayÄ±sÄ± > 3",
            ],
            monitoring_commands=[
                "watch -n 30 'kubectl top pods -n prod -l app=<app>'",
                "kubectl logs -f deployment/<app> -n prod | grep -i 'oom\\|killed\\|memory'",
            ],
            post_mortem_checklist=[
                "Memory leak root cause belirlendi mi?",
                "Resource limits production profiling ile gÃ¼ncellendi mi?",
                "Alert eÅŸikleri dÃ¼zeltildi mi?",
                "Load test ile yeni limitler doÄŸrulandÄ± mÄ±?",
            ],
        )

    # â”€â”€ Database Cascade â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _database_cascade(self, det: CascadeDetectionResult) -> Runbook:
        steps = [
            RunbookStep(
                order=1,
                title="Idle DB BaÄŸlantÄ±larÄ±nÄ± SonlandÄ±r",
                description="5 dakikadan eski idle baÄŸlantÄ±larÄ± temizle. Connection pool'u flush'la.",
                commands=[
                    "kubectl exec -it <postgres-pod> -- psql -c \"SELECT pg_terminate_backend(pid) "
                    "FROM pg_stat_activity WHERE state='idle' AND state_change < NOW() - INTERVAL '5 minutes';\"",
                    "kubectl exec -it <postgres-pod> -- psql -c \"SELECT count(*) FROM pg_stat_activity;\"",
                ],
                phase="PHASE_1",
                estimated_minutes=2,
                verification="Active connections < max_connections * 0.8",
            ),
            RunbookStep(
                order=2,
                title="Connection Pool Boyutunu ArtÄ±r",
                description="PostgreSQL max_connections ve uygulama pool size'Ä± artÄ±r.",
                commands=[
                    "# PostgreSQL: ALTER SYSTEM SET max_connections = 200; SELECT pg_reload_conf();",
                    "# App config: pool_size=100, max_overflow=50, pool_timeout=30",
                    "# PgBouncer kullanÄ±lÄ±yorsa: max_client_conn=200, default_pool_size=50",
                ],
                phase="PHASE_2",
                estimated_minutes=3,
                requires_confirmation=True,
                rollback_command="ALTER SYSTEM SET max_connections = 100; SELECT pg_reload_conf();",
            ),
            RunbookStep(
                order=3,
                title="Health Check ile DB EriÅŸim DoÄŸrula",
                description="PostgreSQL health check endpoint'ini kontrol et.",
                commands=[
                    "kubectl exec -it <postgres-pod> -- pg_isready -h localhost -p 5432",
                    "curl -f http://<postgres-service>:5432/health || echo 'DB UNREACHABLE'",
                    "kubectl exec -it <postgres-pod> -- psql -c 'SELECT 1 AS health_check;'",
                ],
                phase="PHASE_2",
                estimated_minutes=1,
                verification="pg_isready returns 'accepting connections'",
            ),
            RunbookStep(
                order=4,
                title="DB-BaÄŸÄ±mlÄ± Servisleri Restart Et",
                description="Connection pool reset iÃ§in uygulama pod'larÄ±nÄ± sÄ±ralÄ± restart et.",
                commands=[
                    "kubectl rollout restart deployment/<app> -n prod",
                    "kubectl rollout status deployment/<app> -n prod --timeout=120s",
                ],
                phase="PHASE_3",
                estimated_minutes=3,
                verification="kubectl get pods -l app=<app> â†’ all Running, 0 restarts",
            ),
            RunbookStep(
                order=5,
                title="Connection Leak Tespiti",
                description="BaÄŸlantÄ± leak'i var mÄ± kontrol et. Idle connection sayÄ±sÄ± sÃ¼rekli artÄ±yorsa leak var.",
                commands=[
                    "# Her 30sn'de connection count izle:",
                    "watch -n 30 \"kubectl exec -it <postgres-pod> -- psql -c "
                    "'SELECT state, count(*) FROM pg_stat_activity GROUP BY state;'\"",
                    "# Application-side: connection pool metrics endpoint kontrol et",
                ],
                phase="PHASE_4",
                estimated_minutes=5,
            ),
        ]

        return Runbook(
            id="database_cascade",
            title="ğŸ”´ Database Cascade Failure Recovery",
            severity=det.severity,
            cascade_type=det.cascade_type,
            description=det.description,
            detected_signals=det.detected_signals,
            estimated_recovery_minutes=14,
            steps=steps,
            conditional_actions=[
                {"condition": "max_connections hÃ¢lÃ¢ yetersiz", "action": "PgBouncer/ProxySQL connection pooler ekle"},
                {"condition": "Connection leak doÄŸrulandÄ±", "action": "Hotfix: connection close/dispose ekle + deploy"},
                {"condition": "DB disk dolu", "action": "VACUUM FULL + eski verileri archive et"},
            ],
            rollback_triggers=[
                "5dk iÃ§inde connection count tekrar max'a ulaÅŸÄ±rsa",
                "DB health check baÅŸarÄ±sÄ±z olursa",
                "Uygulama pod'larÄ± CrashLoopBackOff'a girerse",
            ],
            monitoring_commands=[
                "watch -n 30 \"kubectl exec <postgres-pod> -- psql -c 'SELECT count(*), state FROM pg_stat_activity GROUP BY state;'\"",
                "kubectl logs -f deployment/<app> -n prod | grep -i 'connection\\|pool\\|timeout'",
            ],
            post_mortem_checklist=[
                "Connection leak root cause bulundu mu?",
                "Pool size production profiling ile belirlendi mi?",
                "Connection lifetime ve idle timeout ayarlandÄ± mÄ±?",
                "PgBouncer gibi connection pooler ihtiyacÄ± var mÄ±?",
            ],
        )

    # â”€â”€ Disk Pressure â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _disk_pressure(self, det: CascadeDetectionResult) -> Runbook:
        steps = [
            RunbookStep(
                order=1,
                title="Disk KullanÄ±mÄ±nÄ± Tespit Et",
                description="Hangi dizin/volume en Ã§ok yer kaplÄ±yor belirle.",
                commands=[
                    "df -h /dev/sda1 /var/log /var/lib/docker",
                    "du -sh /var/log/* /var/lib/docker/* | sort -rh | head -20",
                ],
                phase="PHASE_1",
                estimated_minutes=1,
            ),
            RunbookStep(
                order=2,
                title="Docker Temizlik",
                description="KullanÄ±lmayan Docker image, container ve volume'larÄ± sil.",
                commands=[
                    "docker system prune -af --volumes",
                    "docker image prune -af  # Dangling images",
                    "docker volume prune -f  # Orphan volumes",
                ],
                phase="PHASE_2",
                estimated_minutes=3,
                verification="df -h â†’ disk usage < %80",
            ),
            RunbookStep(
                order=3,
                title="Log Temizlik + Rotation",
                description="Eski loglarÄ± temizle ve logrotate yapÄ±landÄ±r.",
                commands=[
                    "journalctl --vacuum-time=2d  # Journal 2 gÃ¼nden eski sil",
                    "find /var/log -name '*.log' -mtime +7 -delete  # 7 gÃ¼nden eski loglar",
                    "find /var/log -name '*.gz' -mtime +3 -delete  # Eski compressed loglar",
                    "# KalÄ±cÄ±: logrotate config ekle:",
                    "# /etc/logrotate.d/application â†’ daily, rotate 7, compress, maxsize 100M",
                ],
                phase="PHASE_2",
                estimated_minutes=2,
            ),
            RunbookStep(
                order=4,
                title="File Descriptor Limiti ArtÄ±r",
                description="EÄŸer 'too many open files' hatasÄ± da varsa ulimit'i artÄ±r.",
                commands=[
                    "ulimit -n 65536  # GeÃ§ici (mevcut session)",
                    "echo '* soft nofile 65536' >> /etc/security/limits.conf  # KalÄ±cÄ±",
                    "echo '* hard nofile 65536' >> /etc/security/limits.conf",
                    "# Kontrol: cat /proc/<pid>/limits | grep 'open files'",
                ],
                phase="PHASE_2",
                estimated_minutes=1,
            ),
            RunbookStep(
                order=5,
                title="Disk Alert EÅŸiÄŸini DÃ¼ÅŸÃ¼r (%80)",
                description="Erken uyarÄ± iÃ§in disk alert eÅŸiÄŸini %80'e dÃ¼ÅŸÃ¼r.",
                commands=[
                    "# Prometheus: disk_usage_percent > 80 (eski: 95)",
                    "# Node Exporter: node_filesystem_avail_bytes monitoring",
                ],
                phase="PHASE_4",
                estimated_minutes=1,
            ),
        ]

        return Runbook(
            id="disk_pressure",
            title="ğŸ”´ Disk Pressure Crisis Recovery",
            severity=det.severity,
            cascade_type=det.cascade_type,
            description=det.description,
            detected_signals=det.detected_signals,
            estimated_recovery_minutes=8,
            steps=steps,
            conditional_actions=[
                {"condition": "Disk hÃ¢lÃ¢ %95+", "action": "Node drain + yeni node provision et"},
                {"condition": "Docker overlay2 ÅŸiÅŸmiÅŸ", "action": "docker system prune + storage driver kontrol"},
                {"condition": "DB WAL dosyalarÄ± bÃ¼yÃ¼mÃ¼ÅŸ", "action": "pg_archivecleanup + checkpoint_segments ayarla"},
            ],
            rollback_triggers=[
                "5dk iÃ§inde disk yine %95 dolarsa",
                "Servisler write failure vermeye devam ederse",
            ],
            monitoring_commands=[
                "watch -n 30 'df -h /dev/sda1 && du -sh /var/log /var/lib/docker'",
            ],
            post_mortem_checklist=[
                "Log rotation dÃ¼zgÃ¼n Ã§alÄ±ÅŸÄ±yor mu?",
                "Disk kapasitesi yeterli mi, uzun vade artÄ±ÅŸ gerekli mi?",
                "Monitoring alert eÅŸikleri dÃ¼zeltildi mi?",
                "GeÃ§ici dosya temizleme cron job'Ä± eklendi mi?",
            ],
        )

    # â”€â”€ Network / TLS Cascade â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _network_tls_cascade(self, det: CascadeDetectionResult) -> Runbook:
        steps = [
            RunbookStep(
                order=1,
                title="SSL Sertifika Durumunu Kontrol Et",
                description="Sertifika sÃ¼resi dolmuÅŸ mu, ne zaman doluyor kontrol et.",
                commands=[
                    "openssl s_client -connect <domain>:443 -servername <domain> 2>/dev/null | "
                    "openssl x509 -noout -dates",
                    "# Kubernetes Secret kontrol:",
                    "kubectl get secret <tls-secret> -n prod -o jsonpath='{.data.tls\\.crt}' | "
                    "base64 -d | openssl x509 -noout -dates",
                ],
                phase="PHASE_1",
                estimated_minutes=1,
            ),
            RunbookStep(
                order=2,
                title="Sertifika Yenile",
                description="Let's Encrypt veya manual sertifika yenileme.",
                commands=[
                    "certbot renew --force-renewal",
                    "# veya manual cert ile Kubernetes secret gÃ¼ncelle:",
                    "kubectl create secret tls <secret-name> --cert=cert.pem --key=key.pem "
                    "--dry-run=client -o yaml | kubectl apply -f -",
                    "# cert-manager varsa:",
                    "kubectl delete certificate <cert-name> -n prod  # Recreate trigger",
                ],
                phase="PHASE_2",
                estimated_minutes=3,
                requires_confirmation=True,
                verification="openssl s_client -connect <domain>:443 â†’ notAfter > now + 30 days",
            ),
            RunbookStep(
                order=3,
                title="Nginx / Ingress Reload",
                description="Yeni sertifikayÄ± yÃ¼klemek iÃ§in ingress controller'Ä± reload et.",
                commands=[
                    "kubectl rollout restart deployment/nginx-ingress-controller -n ingress-nginx",
                    "# veya bare metal nginx: nginx -s reload",
                    "# Ingress annotation gÃ¼ncellemesi ile de tetiklenebilir",
                ],
                phase="PHASE_3",
                estimated_minutes=2,
                verification="curl -vI https://<domain> 2>&1 | grep 'SSL connection'",
            ),
            RunbookStep(
                order=4,
                title="Upstream Servis Durumunu DoÄŸrula",
                description="Backend servislerinin upstream olarak eriÅŸilebilir olduÄŸunu doÄŸrula.",
                commands=[
                    "curl -f http://<backend-service>:<port>/health",
                    "kubectl get endpoints <service-name> -n prod",
                    "# Nginx upstream check:",
                    "kubectl logs deployment/nginx -n ingress-nginx --tail=20 | grep upstream",
                ],
                phase="PHASE_3",
                estimated_minutes=2,
            ),
            RunbookStep(
                order=5,
                title="Trafik Kademeli AÃ§",
                description="SSL dÃ¼zeldikten sonra trafiÄŸi kademeli aÃ§, 503 yoksa tam aÃ§.",
                commands=[
                    "# Rate limit ile baÅŸla:",
                    "kubectl annotate ingress <app> nginx.ingress.kubernetes.io/rate-limit='10' --overwrite",
                    "# 2dk izle, 503 yoksa kaldÄ±r:",
                    "kubectl annotate ingress <app> nginx.ingress.kubernetes.io/rate-limit- --overwrite",
                ],
                phase="PHASE_3",
                estimated_minutes=3,
            ),
        ]

        return Runbook(
            id="network_tls_cascade",
            title="ğŸ”´ Network / TLS Cascade Recovery",
            severity=det.severity,
            cascade_type=det.cascade_type,
            description=det.description,
            detected_signals=det.detected_signals,
            estimated_recovery_minutes=11,
            steps=steps,
            conditional_actions=[
                {"condition": "SSL handshake hÃ¢lÃ¢ fail", "action": "Sertifika chain eksik mi kontrol et (intermediate cert)"},
                {"condition": "Upstream 502 devam ediyor", "action": "Backend pod'larÄ± restart + health check kontrol"},
                {"condition": "DNS propagation sorunu", "action": "DNS TTL dÃ¼ÅŸÃ¼r + alternatif DNS provider dene"},
            ],
            rollback_triggers=[
                "Yeni sertifika da baÅŸarÄ±sÄ±z olursa",
                "10dk iÃ§inde 503 oranÄ± > %5",
            ],
            monitoring_commands=[
                "watch -n 30 'curl -sI https://<domain> | head -3 && kubectl get pods -n ingress-nginx'",
            ],
            post_mortem_checklist=[
                "Sertifika auto-renewal neden baÅŸarÄ±sÄ±z oldu?",
                "cert-manager veya certbot cronjob aktif mi?",
                "DNS validation token'Ä± gÃ¼ncel mi?",
                "Sertifika expiry alert'i var mÄ± (30, 14, 7 gÃ¼n Ã¶nceden)?",
            ],
        )

    # â”€â”€ Resource Exhaustion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _resource_exhaustion(self, det: CascadeDetectionResult) -> Runbook:
        steps = [
            RunbookStep(
                order=1,
                title="File Descriptor ve Connection Durumunu Tespit Et",
                description="Hangi kaynaklar limitinde tespit et.",
                commands=[
                    "cat /proc/sys/fs/file-nr  # allocated / max",
                    "lsof | wc -l  # Total open files",
                    "ss -s  # Socket summary",
                    "kubectl exec <postgres-pod> -- psql -c 'SHOW max_connections;'",
                    "kubectl exec <postgres-pod> -- psql -c 'SELECT count(*) FROM pg_stat_activity;'",
                ],
                phase="PHASE_1",
                estimated_minutes=2,
            ),
            RunbookStep(
                order=2,
                title="File Descriptor Limiti ArtÄ±r",
                description="Ulimit artÄ±r + systemd service limit gÃ¼ncelle.",
                commands=[
                    "ulimit -n 65536",
                    "echo '* soft nofile 65536' >> /etc/security/limits.conf",
                    "echo '* hard nofile 65536' >> /etc/security/limits.conf",
                    "# systemd service: LimitNOFILE=65536 ekle",
                    "systemctl daemon-reload && systemctl restart <service>",
                ],
                phase="PHASE_2",
                estimated_minutes=2,
            ),
            RunbookStep(
                order=3,
                title="Idle BaÄŸlantÄ±larÄ± Temizle",
                description="DB, Redis ve aÄŸ baÄŸlantÄ±larÄ±nda idle olanlarÄ± sonlandÄ±r.",
                commands=[
                    "# PostgreSQL idle connections:",
                    "kubectl exec <postgres-pod> -- psql -c \"SELECT pg_terminate_backend(pid) "
                    "FROM pg_stat_activity WHERE state='idle' AND state_change < NOW() - INTERVAL '5 min';\"",
                    "# Redis connections: redis-cli CLIENT LIST | grep idle | wc -l",
                    "# TCP connections: ss -tnp state time-wait | wc -l",
                ],
                phase="PHASE_2",
                estimated_minutes=2,
            ),
            RunbookStep(
                order=4,
                title="Connection Pool + Timeout AyarlarÄ±",
                description="BaÄŸlantÄ± havuzu boyutlarÄ±nÄ± ve timeout'larÄ± optimize et.",
                commands=[
                    "# DB: max_connections=200, idle_timeout=60s, connection_lifetime=30min",
                    "# Redis: maxclients 10000, timeout 300",
                    "# App: pool_size=50, pool_recycle=1800, pool_pre_ping=true",
                ],
                phase="PHASE_3",
                estimated_minutes=3,
                requires_confirmation=True,
            ),
        ]

        return Runbook(
            id="resource_exhaustion",
            title="ğŸŸ  Resource Exhaustion Storm Recovery",
            severity=det.severity,
            cascade_type=det.cascade_type,
            description=det.description,
            detected_signals=det.detected_signals,
            estimated_recovery_minutes=9,
            steps=steps,
            conditional_actions=[
                {"condition": "Leak devam ediyor", "action": "lsof -p <pid> ile hangi dosyalar aÃ§Ä±k tespit et"},
                {"condition": "TCP TIME_WAIT Ã§ok fazla", "action": "net.ipv4.tcp_tw_reuse=1 kernel param"},
            ],
            rollback_triggers=[
                "5dk iÃ§inde file descriptor tekrar limit'e ulaÅŸÄ±rsa",
                "Connection count sÃ¼rekli artÄ±yorsa (leak)",
            ],
            monitoring_commands=[
                "watch -n 30 'cat /proc/sys/fs/file-nr && ss -s | head -5'",
            ],
            post_mortem_checklist=[
                "File/socket leak root cause bulundu mu?",
                "Connection pool parametreleri optimize edildi mi?",
                "OS-level limit'ler kalÄ±cÄ± ÅŸekilde artÄ±rÄ±ldÄ± mÄ±?",
            ],
        )

    # â”€â”€ Full Cascade â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _full_cascade(self, det: CascadeDetectionResult) -> Runbook:
        steps = [
            RunbookStep(
                order=1,
                title="âš ï¸ ACÄ°L: TÃ¼m TrafiÄŸi Kes",
                description="Cascade devam ediyor â€” Ã¶nce kanamayÄ± durdur. TÃ¼m ingress trafiÄŸini kes.",
                commands=[
                    "kubectl scale deployment <app> --replicas=0 --namespace=prod",
                    "# ALB/nginx: tÃ¼m upstream'leri down olarak iÅŸaretle",
                    "# WAF: emergency block rule aktif et",
                ],
                phase="PHASE_1",
                estimated_minutes=1,
                verification="kubectl get pods -n prod | grep Running â†’ 0",
            ),
            RunbookStep(
                order=2,
                title="OOM / Restart DÃ¶ngÃ¼sÃ¼nÃ¼ KÄ±r",
                description="TÃ¼m CrashLoopBackOff ve OOMKilled pod'larÄ± force delete.",
                commands=[
                    "kubectl get pods -n prod | grep -E 'OOMKilled|CrashLoop|Error' | "
                    "awk '{print $1}' | xargs kubectl delete pod --force --grace-period=0 -n prod",
                ],
                phase="PHASE_1",
                estimated_minutes=1,
            ),
            RunbookStep(
                order=3,
                title="Resource Quota GeÃ§ici 2x ArtÄ±r",
                description="Memory ve ephemeral storage limitlerini artÄ±r.",
                commands=[
                    "kubectl edit resourcequota -n prod",
                    "# memory.limit: 2x yap",
                    "# ephemeral-storage: 20Gi â†’ 50Gi",
                ],
                phase="PHASE_1",
                estimated_minutes=2,
                requires_confirmation=True,
            ),
            RunbookStep(
                order=4,
                title="Disk + Docker Temizlik",
                description="KullanÄ±lmayan kaynaklarÄ± temizle, log rotation uygula.",
                commands=[
                    "docker system prune -af --volumes",
                    "journalctl --vacuum-time=2d",
                    "find /var/log -name '*.log' -mtime +7 -delete",
                    "du -sh /var/lib/docker /var/log | sort -rh",
                ],
                phase="PHASE_2",
                estimated_minutes=3,
                verification="df -h â†’ disk < %80",
            ),
            RunbookStep(
                order=5,
                title="Connection Pool Flush + DB Temizlik",
                description="Idle DB baÄŸlantÄ±larÄ±nÄ± temizle, Redis cache flush.",
                commands=[
                    "kubectl exec -it <postgres-pod> -- psql -c \"SELECT pg_terminate_backend(pid) "
                    "FROM pg_stat_activity WHERE state='idle' AND state_change < NOW() - INTERVAL '5 min';\"",
                    "redis-cli FLUSHALL  # Sadece cache ise!",
                ],
                phase="PHASE_2",
                estimated_minutes=2,
            ),
            RunbookStep(
                order=6,
                title="File Descriptor Limiti ArtÄ±r",
                description="Too many open files hatasÄ±nÄ± Ã§Ã¶z.",
                commands=[
                    "ulimit -n 65536",
                    "echo '* soft nofile 65536' >> /etc/security/limits.conf",
                    "echo '* hard nofile 65536' >> /etc/security/limits.conf",
                ],
                phase="PHASE_2",
                estimated_minutes=1,
            ),
            RunbookStep(
                order=7,
                title="SSL Sertifika Yenile (varsa expired)",
                description="SSL handshake fail varsa sertifikayÄ± yenile.",
                commands=[
                    "certbot renew --force-renewal",
                    "kubectl create secret tls <secret> --cert=cert.pem --key=key.pem "
                    "--dry-run=client -o yaml | kubectl apply -f -",
                ],
                phase="PHASE_3",
                estimated_minutes=3,
                requires_confirmation=True,
            ),
            RunbookStep(
                order=8,
                title="Data Layer Servisleri BaÅŸlat (SÄ±ralÄ±)",
                description="Ã–nce stateful servisler: PostgreSQL â†’ Redis â†’ Kafka. "
                            "Her birinin healthy olmasÄ±nÄ± bekle.",
                commands=[
                    "kubectl scale statefulset postgres --replicas=1 -n prod",
                    "kubectl wait --for=condition=ready pod/postgres-0 --timeout=120s -n prod",
                    "kubectl scale statefulset redis --replicas=1 -n prod",
                    "kubectl wait --for=condition=ready pod/redis-0 --timeout=60s -n prod",
                    "kubectl scale deployment kafka --replicas=3 -n prod",
                ],
                phase="PHASE_3",
                estimated_minutes=5,
                verification="All stateful pods Ready, health endpoints responding",
            ),
            RunbookStep(
                order=9,
                title="Health Check SONRA App BaÅŸlat (%50)",
                description="Data layer saÄŸlÄ±klÄ±ysa uygulamayÄ± %50 kapasite ile baÅŸlat.",
                commands=[
                    "curl -f http://<postgres-service>:5432/health || exit 1",
                    "curl -f http://<redis-service>:6379/ping || exit 1",
                    "# Her ÅŸey OK ise:",
                    "kubectl scale deployment <app> --replicas=3 -n prod  # %50 kapasite",
                ],
                phase="PHASE_3",
                estimated_minutes=3,
                verification="kubectl get pods -l app=<app> â†’ all Running, 0 restarts",
            ),
            RunbookStep(
                order=10,
                title="Trafik Kademeli AÃ§ (Circuit Breaker ON)",
                description="Rate limit 10 req/s â†’ 100 req/s â†’ normal. Her adÄ±mda 2dk izle.",
                commands=[
                    "kubectl annotate ingress <app> nginx.ingress.kubernetes.io/rate-limit='10' --overwrite",
                    "# 2dk izle: 503/OOM yoksa rate limit artÄ±r",
                    "kubectl annotate ingress <app> nginx.ingress.kubernetes.io/rate-limit='100' --overwrite",
                    "# 2dk daha izle, sorun yoksa kaldÄ±r:",
                    "kubectl annotate ingress <app> nginx.ingress.kubernetes.io/rate-limit- --overwrite",
                ],
                phase="PHASE_3",
                estimated_minutes=6,
            ),
            RunbookStep(
                order=11,
                title="Monitoring + Alert EÅŸiÄŸi GÃ¼ncelle",
                description="Yeni alert eÅŸikleri: Memory %70, Disk %80, CPU %75.",
                commands=[
                    "# Prometheus alert rules gÃ¼ncelle:",
                    "# memory_usage > 70% (eski: 85%)",
                    "# disk_usage > 80% (eski: 95%)",
                    "# cpu_usage > 75% (eski: 90%)",
                    "# Pod restart = 0 hedefi",
                ],
                phase="PHASE_4",
                estimated_minutes=2,
            ),
            RunbookStep(
                order=12,
                title="Resource Limit Profiling",
                description="Production profiling ile optimal resource limit belirle. +50% buffer ekle.",
                commands=[
                    "kubectl set resources deployment <app> "
                    "--limits=memory=1Gi,cpu=1000m --requests=memory=512Mi,cpu=500m -n prod",
                    "# Circuit breaker config:",
                    "# timeout=3s, failure_threshold=50%, retry=3x exponential backoff",
                    "# DB pool: max_connections=100, idle_timeout=60s, connection_lifetime=30min",
                ],
                phase="PHASE_4",
                estimated_minutes=3,
            ),
        ]

        return Runbook(
            id="full_cascade",
            title="ğŸ”´ FULL PRODUCTION CASCADE RECOVERY",
            severity="critical",
            cascade_type=det.cascade_type,
            description=det.description,
            detected_signals=det.detected_signals,
            estimated_recovery_minutes=32,
            steps=steps,
            conditional_actions=[
                {"condition": "disk > %95", "action": "Log rotation + docker prune (adÄ±m 4)"},
                {"condition": "OOMKilled loop", "action": "replicas=0 + memory limit 2x (adÄ±m 1,3)"},
                {"condition": "max_connections aÅŸÄ±ldÄ±", "action": "Idle terminate + pool resize (adÄ±m 5)"},
                {"condition": "503 cascade", "action": "Upstream isolate + bulkhead pattern (adÄ±m 1,10)"},
                {"condition": "SSL handshake fail", "action": "Cert renew + secret update (adÄ±m 7)"},
                {"condition": "GC overhead", "action": "Heap dump + GC tuning"},
            ],
            rollback_triggers=[
                "3dk iÃ§inde OOM tekrarÄ± â†’ Full rollback + traffic external failover",
                "5dk iÃ§inde disk yine %95 â†’ Node drain + yeni node provision",
                "Error rate > %5 after 10dk â†’ Previous deployment restore",
            ],
            monitoring_commands=[
                "watch -n 30 'kubectl top nodes && kubectl top pods -n prod && df -h /dev/sda1'",
                "# Hedef: CPU < %70, Memory < %75, Disk < %80, Pod restarts = 0",
            ],
            post_mortem_checklist=[
                "Cascade'in baÅŸlangÄ±Ã§ noktasÄ± (root trigger) belirlendi mi?",
                "Hangi servis ilk fail etti?",
                "Alert'ler neden daha erken tetiklenmedi?",
                "Resource limit'ler production profiling ile gÃ¼ncellendi mi?",
                "Circuit breaker / bulkhead pattern eklendi mi?",
                "Incident response playbook gÃ¼ncel mi?",
                "Loadtest ile yeni konfigÃ¼rasyon doÄŸrulandÄ± mÄ±?",
            ],
        )

    # â”€â”€ Messaging Infrastructure Down â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _messaging_down(self, det: CascadeDetectionResult) -> Runbook:
        steps = [
            RunbookStep(
                order=1,
                title="Redis / Kafka EriÅŸim KontrolÃ¼",
                description="Redis ve Kafka pod'larÄ±nÄ±n Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± kontrol et.",
                commands=[
                    "kubectl get pods -n prod -l app=redis",
                    "kubectl get pods -n prod -l app=kafka",
                    "redis-cli -h <redis-host> PING",
                    "kafka-broker-api-versions.sh --bootstrap-server <kafka-host>:9092",
                ],
                phase="PHASE_1",
                estimated_minutes=1,
            ),
            RunbookStep(
                order=2,
                title="Redis Restart + Cache Rebuild",
                description="Redis pod'unu restart et, cache cold start'a hazÄ±rlan.",
                commands=[
                    "kubectl rollout restart statefulset/redis -n prod",
                    "kubectl wait --for=condition=ready pod/redis-0 -n prod --timeout=60s",
                    "redis-cli PING  # PONG dÃ¶nmeli",
                    "# Cache warm-up: uygulamada cache priming endpoint varsa Ã§aÄŸÄ±r",
                ],
                phase="PHASE_2",
                estimated_minutes=3,
                verification="redis-cli PING â†’ PONG",
            ),
            RunbookStep(
                order=3,
                title="Kafka Broker'larÄ± BaÅŸlat",
                description="Kafka broker'larÄ±nÄ± sÄ±ralÄ± baÅŸlat, partition rebalance bekle.",
                commands=[
                    "kubectl scale statefulset kafka --replicas=3 -n prod",
                    "# Partition durumunu kontrol et:",
                    "kafka-topics.sh --describe --bootstrap-server <kafka>:9092 | grep -i 'under-replicated'",
                    "# Consumer group lag kontrol:",
                    "kafka-consumer-groups.sh --bootstrap-server <kafka>:9092 --list",
                ],
                phase="PHASE_2",
                estimated_minutes=5,
            ),
            RunbookStep(
                order=4,
                title="Async Servisler Restart",
                description="MesajlaÅŸma altyapÄ±sÄ± saÄŸlÄ±klÄ± olduktan sonra consumer servisleri restart et.",
                commands=[
                    "kubectl rollout restart deployment/<consumer-app> -n prod",
                    "# Consumer lag monitÃ¶r et: lag azalmalÄ±",
                ],
                phase="PHASE_3",
                estimated_minutes=3,
            ),
        ]

        return Runbook(
            id="messaging_down",
            title="ğŸŸ  Messaging Infrastructure Recovery",
            severity=det.severity,
            cascade_type=det.cascade_type,
            description=det.description,
            detected_signals=det.detected_signals,
            estimated_recovery_minutes=12,
            steps=steps,
            conditional_actions=[
                {"condition": "Kafka partition corrupt", "action": "kafka-log-dirs.sh ile tespit + reassign"},
                {"condition": "Redis data loss kabul edilemez", "action": "AOF/RDB restore'dan baÅŸlat"},
            ],
            rollback_triggers=[
                "Redis/Kafka 5dk iÃ§inde tekrar Ã§Ã¶kerse",
                "Consumer lag artmaya devam ederse",
            ],
            monitoring_commands=[
                "watch -n 30 'redis-cli INFO memory | grep used_memory_human && "
                "kafka-consumer-groups.sh --describe --group <group> --bootstrap-server <kafka>:9092'",
            ],
            post_mortem_checklist=[
                "Redis/Kafka neden Ã§Ã¶ktÃ¼ (OOM, disk, network)?",
                "Backpressure mekanizmasÄ± var mÄ±?",
                "Dead letter queue implementasyonu gerekli mi?",
            ],
        )

    # â”€â”€ Upstream 503 Storm â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _upstream_storm(self, det: CascadeDetectionResult) -> Runbook:
        steps = [
            RunbookStep(
                order=1,
                title="Upstream Servis Durumunu Tespit Et",
                description="Hangi upstream'ler down? Nginx error log'larÄ± kontrol et.",
                commands=[
                    "kubectl logs deployment/nginx-ingress-controller -n ingress-nginx --tail=50 "
                    "| grep -E 'upstream|502|503'",
                    "kubectl get endpoints -n prod  # Backend endpoint'leri var mÄ±?",
                ],
                phase="PHASE_1",
                estimated_minutes=1,
            ),
            RunbookStep(
                order=2,
                title="Rate Limiting Aktif Et",
                description="Client retry storm'u durdurmak iÃ§in trafiÄŸi kÄ±s.",
                commands=[
                    "kubectl annotate ingress <app> nginx.ingress.kubernetes.io/rate-limit='10' --overwrite",
                    "# veya nginx level: limit_req zone=one burst=5 nodelay;",
                ],
                phase="PHASE_1",
                estimated_minutes=1,
            ),
            RunbookStep(
                order=3,
                title="Backend Pod'larÄ± Restart + Scale",
                description="Down olan backend servisleri restart et, gerekirse scale up.",
                commands=[
                    "kubectl rollout restart deployment/<backend-app> -n prod",
                    "kubectl rollout status deployment/<backend-app> --timeout=120s",
                    "kubectl scale deployment/<backend-app> --replicas=5 -n prod  # Scale up",
                ],
                phase="PHASE_2",
                estimated_minutes=3,
                verification="kubectl get pods -l app=<backend> â†’ all Running",
            ),
            RunbookStep(
                order=4,
                title="Circuit Breaker + Bulkhead Pattern",
                description="Gelecekteki cascade'leri Ã¶nlemek iÃ§in circuit breaker ekle.",
                commands=[
                    "# Resilience4j / Istio circuit breaker:",
                    "# timeout: 3s, failure_threshold: 50%, recovery: 30s",
                    "# Bulkhead: max concurrent calls = 25 per service",
                    "# Retry: 3x exponential backoff (1s, 2s, 4s)",
                ],
                phase="PHASE_3",
                estimated_minutes=5,
                requires_confirmation=True,
            ),
        ]

        return Runbook(
            id="upstream_storm",
            title="ğŸŸ  Upstream 503 Storm Recovery",
            severity=det.severity,
            cascade_type=det.cascade_type,
            description=det.description,
            detected_signals=det.detected_signals,
            estimated_recovery_minutes=10,
            steps=steps,
            conditional_actions=[
                {"condition": "Backend OOMKilled", "action": "Memory limit artÄ±r + OOM runbook uygula"},
                {"condition": "Retry storm devam", "action": "WAF ile aggressive rate limit"},
            ],
            rollback_triggers=[
                "10dk sonra error rate > %5",
                "Backend pod'larÄ± tekrar fail ederse",
            ],
            monitoring_commands=[
                "watch -n 30 'kubectl logs deployment/nginx --tail=5 -n ingress-nginx | grep -c 503'",
            ],
            post_mortem_checklist=[
                "Upstream neden 503 verdi?",
                "Circuit breaker eklendi mi?",
                "Client-side retry politikasÄ± gÃ¼ncel mi?",
                "Graceful degradation stratejisi var mÄ±?",
            ],
        )

    # â”€â”€ Generic Fallback â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _generic_runbook(self, det: CascadeDetectionResult) -> Runbook:
        """Fallback runbook for unrecognized cascade patterns."""
        steps = [
            RunbookStep(
                order=1,
                title="Durumu DeÄŸerlendir",
                description="Aktif sinyalleri incele ve etkilenen servisleri belirle.",
                commands=[
                    "kubectl get pods -n prod --field-selector=status.phase!=Running",
                    "kubectl top nodes",
                    "kubectl top pods -n prod",
                    "df -h",
                ],
                phase="PHASE_1",
                estimated_minutes=2,
            ),
            RunbookStep(
                order=2,
                title="Acil MÃ¼dahale",
                description="Sinyallere gÃ¶re ilgili kaynaklarÄ± temizle/restart et.",
                commands=[
                    "# Sinyaller: " + ", ".join(det.detected_signals),
                    "kubectl rollout restart deployment/<affected-app> -n prod",
                ],
                phase="PHASE_2",
                estimated_minutes=5,
            ),
            RunbookStep(
                order=3,
                title="DoÄŸrulama ve Ä°zleme",
                description="Servislerin saÄŸlÄ±ÄŸÄ±nÄ± doÄŸrula, 15dk izleme yap.",
                commands=[
                    "kubectl get pods -n prod",
                    "watch -n 30 'kubectl top pods -n prod'",
                ],
                phase="PHASE_3",
                estimated_minutes=5,
            ),
        ]

        return Runbook(
            id="generic",
            title=f"ğŸŸ¡ {det.cascade_type} Recovery",
            severity=det.severity,
            cascade_type=det.cascade_type,
            description=det.description,
            detected_signals=det.detected_signals,
            estimated_recovery_minutes=12,
            steps=steps,
            conditional_actions=[],
            rollback_triggers=["10dk iÃ§inde aynÄ± hatalar tekrarlarsa"],
            monitoring_commands=["watch -n 30 'kubectl get pods -n prod && kubectl top nodes'"],
            post_mortem_checklist=["Root cause analizi yapÄ±ldÄ± mÄ±?", "Alert eÅŸikleri gÃ¼ncellendi mi?"],
        )

    # â”€â”€ Generator Registry â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    _GENERATORS = {
        "oom_kill_loop": _oom_kill_loop,
        "database_cascade": _database_cascade,
        "disk_pressure": _disk_pressure,
        "network_tls_cascade": _network_tls_cascade,
        "resource_exhaustion": _resource_exhaustion,
        "full_cascade": _full_cascade,
        "messaging_down": _messaging_down,
        "upstream_storm": _upstream_storm,
    }
